\section*{Discussion}

We present an entirely new approach to performing and communicating
experimental science, here demonstrated for physiology.  Our use of
typed, functional and reactive programming overcomes at least three
long-standing issues in bioinformatics: the need for a flexible
ontology to share heterogeneous data from physiological experiments
\citep{Amari2002}, a language for describing experiments unambiguously
\citep{Murray-Rust2002}, and an equational formulation of data
provenance \citep{Pool2002}. 

The types we have presented form a linguistic framework and an
ontology for physiology. Thanks to the flexibility of parametric polymorphism,
our ontology can form the basis for the interchange of physiological data
and meta-data without imposing unnecessary constraints on what can be
shared. The ontology is non-hierarchical and would be difficult to
formulate in the various existing semantic web ontology frameworks
(Web Ontology Language, \citealt{owlref}, or Resource Description Framework), which lack
parametric polymorphism and functional abstraction. Nevertheless, by
specifying the categories of mathematical objects that constitute
evidence, it is an ontology in the classical sense of cataloguing the
categories within a specific domain, and providing a vocabulary for
that domain. We emphasise again that it is an ontology of
\emph{evidence}, not of the biological entities that give rise to this
evidence. It is unusual as an ontology for scientific knowledge in
being embedded in a \emph{computational} framework, such that it can
describe not only mathematical objects but also their transformations
and observations.

% HN 2010-11-24: Instead of
%
% Our mathematical definitions are less ambiguous than definitions
% written in plain English, 
% 
% to make it consistent with "unambiguous" above, I propose
%
Our mathematical definitions are unambiguous and concise, unlike
typical definitions written in natural language,
and are more powerful than those specified
by graphical user interfaces or in formal languages that lack a
facility for defining abstractions. Our framework is not only a
theoretical formalism, but also a very practical tool. It is a
collection of computer programs for executing experiments and
analyses, and carrying out data management. Controlling
experimentation and analysis with programs that share data formats can
be highly efficient, and eliminates many sources of human error. Our
experiment definitions have the further advantage that they
\emph{compose}; that is, more complex experiments can be formulated by
joining together elementary building blocks. 

Our full approach is particularly relevant to the execution of very
complex and multi-modal experiments, which may need to be dynamically
reconfigured based on previous observations, or to disambiguate
difficult judgements about evidence \citep{Kriegeskorte2009}. Even
if used separately, however, individual aspects of CoPE can make
distinct contributions to scientific methodology â€” for instance, our
ontology for physiological evidence can be used within more
conventional programming languages or web applications that facilitate
data sharing. In a similar way, the capabilities of CoPE for executing
and analysing experiments could provide a robust core for innovative
graphical user interfaces.

A corollary of our work is that it may be possible in principle to
mechanically verify scientific inference, just as mathematical proofs
can be verified by a proof checker \citep{DeBruijn1968,
  Harrison2009}. It is of course not possible to verify particular
hypotheses about the physical world, or an organism in this way. What
might be verifiable are statements about experiments --- for instance,
that: particular variables were randomly controlled and not observed;
outcomes have not gained correlation due to the analysis procedure;
missing data are accounted for by the statistical model
\citep{Gelman2003}; errors are propagated correctly \citep{Taylor1997};
units of measurement are used consistently \citep{Kennedy1997}; there
is no ``double dipping'' \citep{Kriegeskorte2009}; and, ultimately,
that the observed data support the conclusions drawn. Statistical
analyses address some of these issues in relating observations to
parameter estimation and hypothesis testing. Without knowing
where observations come from, however, it is difficult to ascertain whether
they provide evidence for a given scientific hypothesis
\citep{Pool2002}. Experiment description languages, and the
representation of experimental observations into values of concrete
types (which may not always be real numbers), could play an important
role in such inference. It is likely that at least some aspects of
validation in physiology can be achieved with conservative extensions
of
% the calculus of physiological evidence 
CoPE integrated with statistical inference.

\section*{Methods}

\subsubsection*{Language implementation} 

We have used two different implementation strategies for reasons of
rapid development and execution efficiency. For purposes of
experimentation and simulation, we have implemented a prototype
compiler that can execute some programs that contain signals and
events defined by mutual recursion, as is necessary for many of the
simulations and experiments in this paper. The program is transformed
by the compiler into a normal form that is translated to an imperative
program which iteratively updates variables corresponding to signal
values, with a time step that is set explicitly. The program is
divided into a series of stages, where each stage consists of the
signals and events defined by mutual recursion, subject to the
constraints of input/output sources and sinks. This ensures that
signal expressions can reference values of other signals at arbitrary
time points (possibly in the future) as long as referenced signals are
computed in an earlier stage.

To calculate a new value from existing observations after data
acquisition, we have implemented the calculus of physiological
evidence as a domain-specific language embedded in the purely functional
programming language Haskell. 

For hard real-time dynamic-clamp experiments, we have built a compiler
back-end targeting the LXRT (user-space) interface to the RTAI (Real-time
application interface; http://rtai.org) extensions of the Linux
kernel, and the Comedi (http://comedi.org) interface to data
acquisition hardware. Geometric shapes were rendered using OpenGL
(http://opengl.org).

All code is available at http://github.com/glutamate/bugpan and
released under the GPL.

\subsubsection*{Sources and Sinks}

Sources and sinks 
% HN 2010-11-24: Yes, I can see they can be considered as "annotations"
% in that they are somewhat peripheral to an experiment definition. However,
% they are certainly not void of sematic content relevant to the experiment
% as such! Cf the discussion of idempotency for example. I suggest simply
% not saying anything about the "nature" of sourecs and sinks here.
%
% are annotations to a program that 
%
link the functional equations with the physical world. We stress that they are
not expressions, do not evaluate to values (unlike all other
constructs), and can only be used at the top level. What happens if the
same source is observed more than once in a description of an
experiment?  If the source refers to a single, physical input port
such as a channel of an analog-to-digital converter, the result will
necessarily be the same, because the same entity is being observed
within a single run of the experiment. Such sources are called
\emph{idempotent}.  Idempotency ensures that separate experiments
referring to a common external variable can be composed easily with a
predictable outcome. However, there are other kinds of sources,
notably random sources as discussed below, where idempotency is
\emph{not} desirable. Each occurrence of a non-idempotent source is
thus a separate, independent source, even if the name of the source
and the parameters happen to be the same.

What happens if the same \emph{sink} is defined more than once? One could
imagine combining the defining signals in various ways. For example, in the
case of a simple numerical signal, they could simply be added, mirroring
superposition of waves in the physical world. However, as our signals are more
general, it is not always clear what the appropriate notion of ``addition''
should be. For example, if we have signals carrying images, and we wish to
output these to a single graphical display, it is likely that we also need to
describe aspects such as which one should be ``on top''. Thus, for flexibility
and clarity, combination of output signals has to be described explicitly, and
it is an error to define a sink more than once in an experimental description.

There are also operations in experiments that are not related to real-world
observation or to purely functional computation. One example is sampling from
probability distributions. We have implemented sources corresponding to common
parametrised probability distributions, such that experiments can sample
values from the distributions and use these values in computations or
connect them to sinks. However, these sources are \emph{not} idempotent as it
is important that there are no accidental correlations. Sharing of a single random
signal, when needed, can  be described by binding that signal to a
variable as discussed above and using the variable to refer to the signal
instead of repeating the reference to the random source. In this more general
view, sources and sinks bridge referentially transparent and non-transparent
computations.

\subsubsection*{Locust experiments}

Recordings from locust DCMD neurons were performed as previously
described \citep{Matheson2004}. Briefly, locusts were fixed in
plasticine with the ventral side upwards. The head was fixed with wax
% at a $90^{\circ}$ angle 
and the connectives were exposed through an
incision in the soft tissue of the neck. A pair of silver wire hook
electrodes were placed underneath the connectives and the electrodes
and connectives enclosed in petroleum jelly. The electrode signal was
amplified 1000x and bandpass filtered 50--5000 Hz, before
analog-to-digital conversion at 18 bits and 20 kHz with a National
Instruments PCI-6281 board. The locust was placed in front of a 22''
CRT monitor running with a vertical refresh rate of 160 Hz. All
aspects of the visual stimulus displayed on this monitor and of
the analog-to-digital conversion performed by the National Instruments
board were controlled by programs written in 
% the calculus of physiological evidence
CoPE running on a single computer.

\subsubsection*{Zebrafish experiments}

Intracellular patch-clamp recordings from motor neurons in the spinal
cord from a 2-day old zebrafish embryo were performed as previously
described \citep{McDearmid2006}. We used a National Instruments PCI-6281
board to
record the output from a BioLogic patch-clamp amplifier in
current-clamp mode, filtered at 3kHz and digitised at 10 kHz, with the
output current calculated at the same rate by programs written in
% the calculus of physiological evidence 
CoPE targeted to the RTAI backend (see
above). The measured jitter for updating the output voltage was 6
$\mu$s and was similar to that measured with the RTAI latency test
tool for the experiment control computer.

\section*{Acknowledgements} 

We would like to thank Jonathan McDearmid for help with the Zebrafish
recordings and Angus Silver, Guy Billings, Antonia Hamilton, Nick
Hartell and Rodrigo Quian Quiroga for critical comments on the
manuscript. This work was funded by a Human Frontier Science Project
fellowship to T.N., a Biotechnology and Biological Sciences Research
Council grant to T.M. and T.N., and Engineering and Physical Sciences Research
Council grants to H.N.

\section*{Author Contributions}  
T.N. designed and implemented CoPE, carried out the experiments and
data analyses, and wrote the draft of the paper. H.N. contributed to
the language design, helped clarify the semantics, and wrote several
sections of the manuscript. T.M. contributed to the design of the
experiments and the data analysis, and made extensive comments on
drafts of the manuscript. All authors obtained grant funding to
support this project as described in the acknowledgements.


