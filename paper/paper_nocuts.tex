\documentclass[11pt]{article}
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}

\newlength{\lwidth}\setlength{\lwidth}{4.5cm}
\newlength{\cwidth}\setlength{\cwidth}{8mm} % 3mm

\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%







%%format ?? = "\,\text{?`}\!\text{?}"

\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{setspace}
\usepackage{verbatim}
\usepackage[final]{pdfpages}
\usepackage[square, comma, numbers, compress]{natbib}
%\usepackage{citesupernumber}
\usepackage{url}
\usepackage{graphicx}
%\linenumbers
%\usepackage{epsfig}
\doublespacing \title{A formal mathematical framework for
  physiological observations, experiments and analyses}

\author{Thomas A. Nielsen, Henrik Nilsson and Tom Matheson}
\pagestyle{myheadings}
\markboth{Framework for experiments in physiology}{Framework for experiments in physiology}
\begin{document}
\begin{titlepage}

\vspace{50 mm}
\begin{center}{\LARGE {\bf A formal mathematical framework for
  physiological observations, experiments and analyses}}
\end{center}
\vspace{50 mm}

\begin{center}{\large Thomas A. Nielsen$^{1}$, Henrik Nilsson$^2$ and Tom Matheson$^{1*}$}
\end{center}
\vspace{27 mm}

\begin{flushleft}
RUNNING TITLE: Framework for experiments in physiology
\end{flushleft}

\vspace{27 mm}


\begin{flushleft}
1. Department of Biology, University of Leicester, University Road, Leicester LE1 7RH

2. School of Computer Science, University of Nottingham, Jubilee Campus, Nottingham NG8 1BB
\vspace{50 mm}

$^*$ To whom correspondence should be sent (tm75@le.ac.uk)

\end{flushleft}

\end{titlepage}
\section*{Abstract}
 
Experiments can be complex and produce large volumes of heterogeneous
data, which makes their execution, analysis, independent replication
and meta-analysis difficult. We propose a mathematical model for
experimentation and analysis in physiology that addresses these
problems. We show that experiments can be composed from time-dependent
quantities, and be expressed as purely mathematical equations. Our
structure for representing physiological observations can carry
information of any type and therefore provides a precise ontology for
a wide range of observations. Our framework is concise, allowing
entire experiments to be defined unambiguously in a few equations. To
demonstrate that our approach can be implemented, we show the full
equations we have used to run and analyse two non-trivial experiments
describing visually stimulated neuronal responses and dynamic clamp of
vertebrate neurons. Our ideas could provide a theoretical basis for
developing new standards of data acquisition, analysis and
communication in neurophysiology.

\pagebreak

\section*{Introduction}

Reproducibility and transparency are cornerstones of the scientific
method. As scientific experiments and analysis become increasingly
complex, reliant on computer code and produce larger volumes of data,
the feasibility of independent verification and replication has -- in
practice -- been undermined. Primary data sharing is now standard in
applications of high-throughput biology, but not in the many fields
that produce heterogeneous observations \citep{Gardner2005,
  Tukey1962}. Even when raw data and code used for experiments and
analysis are fully disclosed, only a minority of findings can be
reproduced without discrepancies \citep{Ioannidis2008,Baggerly2009,
  McCullough2007}. It is often not realistic to verify that computer
code used in analyses correctly implements an intended mathematical
algorithm, yet errors can undermine a large body of work
\citep{Chang2006}. The combination of bias, human error, and unverified
software, has led to the suggestion that many published research
findings are flawed \citep{Ioannidis2005, Merali2010}.

Some of these problems may be mitigated by developing explicit models
of experimentation, evidence representation and analysis. A good model
should simultaneously: (i) introduce a system of categorisation
directly relevant to the scientific field, such that scientists can
define experiments and reason about observations in familiar terms,
(ii) be machine executable, therefore unambiguous and practically
useful, and (iii) consist exclusively of terms that directly
correspond to mathematical entities, enabling algebraic reasoning
about and manipulation of procedures.  Experiments are difficult to
formalise in terms of relations between mathematical objects because
they produce heterogeneous data \citep{Tukey1962}, and because they
interact with the physical world. In creating a mathematical framework
for experiments, we take advantage of progress in embedding input and
output \citep{PeytonJones2002, Wadler1995} into programming languages
where the only mechanism of computation is the evaluation of
mathematical functions \citep{Church1941}.

Here, we define a formal framework for physiology
that satisfies the above criteria. We show that there
is a large conceptual overlap between physiological experimentation
and Functional Reactive Programming (FRP; \citep{Elliott1997,
  Nilsson2002}), a concise and purely functional formulation of
time-dependent reactive computer programs. Consequently, physiological
experiments can be concisely defined in the vocabulary of
\emph{signals} and \emph{events} introduced by FRP. Such a language
does not describe the physical components of biological organisms; it
has no concept of networks, cells or proteins. Instead it describes
the observation and calculation of the mathematical objects that
constitute physiological evidence (``observations'').

Our framework provides:

(i) An explicitly defined ontology of physiological
observations. Physiological databases have not been widely adopted
\citep{Herz2008, Amari2002} despite many candidates \citep{Jessop2010,
  Teeters2008, Frishkoff2009, Katz2010}.  This constrasts with
bioinformatics and neuroanatomy, where databases are routinely used
\citep{Rodriguez-Tome1996, Ascoli2007}. We suggest that a flexible,
concise and simple structure for physiological quantities can remedy
some of the shortcomings \citep{Gardner2005, Amari2002} of existing
databases and thus facilitate the sharing of physiological data and
meta-data \citep{Insel2003}.

(ii) A concise language for describing complex experiments and
analysis procedures in physiology using only mathematical
equations. Experimental protocols can be communicated unambiguously,
highlighting differences between studies and facilitating replication
and meta-analysis. The provenance \citep{Pool2002,MacKenzie-Graham2008,
  VanHorn2009} of \emph{any} observation can be extracted as a single
equation that includes post-acquisition processing and censoring. In
addition, analysis procedures in languages with a clear mathematical
denotation are verifiable since their implementation closely
follows their specification \citep{Bird1996}.

(iii) The theoretical basis for new tools that are practical, powerful
and generalise to complex and multi-modal experiments. To demonstrate
this, we have implemented our framework as a new programming language
and used it for non-trivial neurophysiological experiments and data
analyses. A strength of our approach is that its individual elements
could, alternatively, be adopted separately or in different ways to
suit different demands.

\section*{Results}

To introduce the calculus of physiological evidence (CoPE), we first
define some terminology and basic concepts. We assume that \emph{time}
is global and is represented by a real number, as in classical
physics. An \emph{experiment} is an interaction between an observer
and a number of organisms during a defined time period. An experiment
consists of one or more \emph{trials}: non-overlapping time periods
during which the observer is running a \emph{program} --- instructions
for manipulating the environment and for constructing mathematical
objects, the \emph{observations}. The \emph{analyses} are further
programs to be run during or after the experiment that construct other
mathematical objects pertaining to the experiment. In the sections
that follow, we give precise definitions of these concepts using terms
from programming language theory and type theory, while providing
an introduction to the terms for a general audience.

\subsubsection*{Type theory for physiological evidence}

What kinds of mathematical objects can be used as physiological
evidence? We answer this question within simple type theory
\citep{Pierce2002, Hindley2008}, which introduces an intuitive
classification of mathematical objects by assigning to every object
exactly one \emph{type}. These types include base types, such as
integers \ensuremath{\mathbb{Z}}, real numbers \ensuremath{\mathbb{R}}, text strings \ensuremath{\Conid{String}} and the
Boolean type \ensuremath{\Conid{Bool}} with the two values \ensuremath{\Conid{True}} and \ensuremath{\Conid{False}}. These base
types are familiar to users of most programming languages. In
addition, modern type systems, including simple type theory, allow
types to be arbitrarily combined in several ways. For instance, if
\ensuremath{\alpha} and \ensuremath{\beta} are types, the type \ensuremath{\alpha\;\!\!\times\!\!\;\beta} is the pair
formed by one element of \ensuremath{\alpha} and one of \ensuremath{\beta}; \ensuremath{[\mskip1.5mu \alpha\mskip1.5mu]} is a
list of \ensuremath{\alpha}s; and \ensuremath{\alpha\to \beta} is the type of functions that
calculate a value in the type \ensuremath{\beta} from a value in \ensuremath{\alpha}. The
ability to write flexible type schemata and generic functions
containing type variables ($\alpha, \beta, \ldots$), which can later
be substituted with any concrete type, is called ``parametric
polymorphism''\citep{Pierce2002} and is essential to the simplicity
and flexibility of CoPE.

We distinguish three type schemata in which physiological evidence can
be values. These differ in the manner in which measurements appear in
a temporal context, but which all derive their flexibility from
parametric polymorphism. \emph{Signals} capture the notion of
quantities that change in time. In physiology, observed time-varying
quantities often represent scalar quantities, such as membrane
voltages or muscle force, but there are also examples of non-scalar
signals such as the two- or three dimensional location of an animal or
of a body part. Here, we generalise this notion such that for
\emph{any} type \ensuremath{\alpha}, a signal of \ensuremath{\alpha} is defined as a
\emph{function} from time to a value in \ensuremath{\alpha}, written formally as:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Conid{Signal}\;\alpha\mathrel{=}\Conid{Time}\to \alpha}$
\end{tabbing}For instance, the output of a differential
voltage amplifier might be captured in a \ensuremath{\Conid{Signal}\;\mathbb{R}}.

To model occurrences pertaining to specific instances in time,
FRP defines \emph{events} as a list of pairs of time points and values in a
type \ensuremath{\alpha}, called the ``tags'':
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Conid{Event}\;\alpha\mathrel{=}[\mskip1.5mu \Conid{Time}\;\!\!\times\!\!\;\alpha\mskip1.5mu]}$
\end{tabbing}For example, an event can be constructed from a number-valued signal
that represents the time of the largest amplitude value of of the
signal, with that amplitude in the tag. Events that do not have a
value of interest to associate with the time point at which it
occurred, can be tagged with the unit type \ensuremath{()} which has only one
element (that is, no information). Events can therefore represent
measurements where the principal information is \emph{when} something
happened, or measurements that concern \emph{what} happened.

A third kind of information describes the properties of whole time
periods. We define a \emph{duration} of type \ensuremath{\alpha} as a list of pairs, of
which the first component is a pair denoting a start time and an end
time. The last component is again a value of any type \ensuremath{\alpha}:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Conid{Duration}\;\alpha\mathrel{=}[\mskip1.5mu \Conid{Time}\;\!\!\times\!\!\;\Conid{Time}\;\!\!\times\!\!\;\alpha\mskip1.5mu]}$
\end{tabbing}Durations are useful for manipulating information about a whole trial
or a single annotation of an entire experiment, but could also be
observations in their own right, such as open times of individual ion
channels, or periods in which activity of a system exceeds a set
threshold (e.g during bursts of action potentials). Lastly, durations
could be used for information that spans multiple trials but not an
entire experiment --- for instance, the presence or absence of a drug.

Since signals, events and durations can be instantiated for any type,
they form a simple but flexible framework for representing many
physiological quantities. We show a list of such examples primarily
drawn from neurophysiology in Table 1. A framework in any type system
that does not support parametric polymorphism would have to represent
these quantities fundamentally differently, thus removing the
possibility of re-using common analysis procedures. Although
parametric polymorphism is conceptually simple and the distinctions we
are introducing are intuitive, common biomedical
ontologies \citep{owlref} \emph{cannot} accommodate these definitions.

\subsubsection*{Calculating with signals and events}

From direct observations, one often needs to process events and
signals, create new events from signals, filter data and calculate
statistics. Here, we formulate these transformations in terms of the
lambda calculus \citep{Church1941}, a family of formal languages for
computation based solely on evaluating functions.  These languages,
unlike conventional programming languages, retain an important
characteristic of mathematics: a term can freely be replaced by
another term with identical meaning.
% HN 2010-09-30: Always "substitute for"
This property (referential transparency; \citep{Whitehead1927})
% HN 2010-11-10: "enables" is a bit too strong. For example, it is certainly
% *possible* to reason formally about imperative code. 
facilitates algebraic manipulation of and reasoning about
programs \citep{Bird1996}. The lambda calculus allows functions to be
used as first class entities: that is, they can be referenced by
variables and passed as arguments to other functions. On the other
hand, the lambda calculus disallows changing the value of variables or
global states. These properties together mean that the lambda calculus
combines verifiable correctness with a high level of abstraction,
leading to programs that are in 
% HN 2010-11-24: Note: practice is the noun, practise the verb 
practice more concise \citep{Hughes1989} than those written in
conventional programming languages. The lambda calculus or variants
thereof has been used as a foundation for mathematics
\citep{Martin-Lof1985}, classical \citep{Sussman2001} and quantum
\citep{Karczmarczuk2003} mechanics, evolutionary biochemistry
\citep{Fontana1994}, mechanized theorem provers \citep{DeBruijn1968,
  Harrison2009} and functional programming languages
\citep{McCarthy1960}.

In the lambda calculus, calculations are performed by function
abstraction and application. \ensuremath{\lambda \Varid{x}\to \Varid{e}} denotes the function with
argument \ensuremath{\Varid{x}} and body \ensuremath{\Varid{e}}, and \ensuremath{\Varid{f}\;\Varid{e}} the application of the function
\ensuremath{\Varid{f}} to the expression \ensuremath{\Varid{e}} (more conventionally written $f(e)$). For
instance, the function \ensuremath{\Varid{add2}\mathrel{=}\lambda \Varid{x}\to \Varid{x}\mathbin{+}\mathrm{2}} adds two to its argument;
hence \ensuremath{\Varid{add2}\;\mathrm{3}\mathrel{=}(\lambda \Varid{x}\to \Varid{x}\mathbin{+}\mathrm{2})\;\mathrm{3}\mathrel{=}\mathrm{3}\mathbin{+}\mathrm{2}} by substituting arguments in the
function body.

We now present the concrete syntax of CoPE, in which we the lambda
calculus with constructs to define and manipulate signals and
events. 
% HN 2010-11-24: Old:
% 
% This calculus borrows some concepts from earlier versions of
% FRP, but it emphasises signals and events as mathematical objects in
% themselves, rather than as control structures for creating reactive
% systems \citep{Elliott1997, Nilsson2002}. 
% 
% I think it's important to make it very clear that CoPE is not FRP:
%
This calculus borrows some concepts from earlier versions of FRP, but
focuses exclusively on signals and events as mathematical objects and
their relations.  It does noy have any control structures for
describing sequences of system configurations, where a signal
expression depends on the occurrence of events \citep{Elliott1997,
  Nilsson2002}, although such constructs may be useful for
simulations. As a result, CoPE is quite different from conventional
FRP, which is also reflected in its implementation.

Let the construct \ensuremath{\{\!:\!\;\Varid{e}\;\!:\!\}} denote a signal with the value of
the expression \ensuremath{\Varid{e}} at every time point, and let the construct \ensuremath{\langle:\Varid{s}:\rangle} denote the current value of the signal \ensuremath{\Varid{s}} in the temporal context
created by the surrounding \ensuremath{\{\!:\!} \ldots \ensuremath{\!:\!\}} braces. For
instance,
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\{\!:\!\;\mathrm{1}\;\!:\!\}}$
\end{tabbing}denotes the signal that always has the value 1; and the function \ensuremath{\Varid{smap}}
defined as
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{smap}\mathrel{=}\lambda \Varid{f}\to \lambda \Varid{s}\to \{\!:\!\;\Varid{f}\langle:\Varid{s}:\rangle\!:\!\}}$
\end{tabbing}transforms, for any two types \ensuremath{\alpha} and \ensuremath{\beta}, the signal \ensuremath{\Varid{s}} of \ensuremath{\alpha}
into a signal of \ensuremath{\beta} by applying the function \ensuremath{\Varid{f}} of type \ensuremath{\alpha\to \beta} to the value of the signal at every time point.

The differential operator \ensuremath{\Conid{D}} differentiates a real-valued signal with
respect to time, such that \ensuremath{\Conid{D}\;\Varid{s}} denotes its first derivative and \ensuremath{\Conid{D}\;\Conid{D}\;\Varid{s}} the second derivative of the signal \ensuremath{\Varid{s}}. When the differential
operator appears on the left-hand side of a definition, it
introduces a differential equation (see Example 2 below).

Events and durations can be manipulated as \emph{lists}. Thus, a large
number of transformations can be defined with simple recursive
equations including filters, folds and scans that are pivotal in functional
programming languages \citep{Hughes1989}. In addition, we have added a
special construct to detect events from existing signals. For
instance, a threshold detector generates an occurrence of an event
whenever the value of a signal crosses a specific level from below.
Here, we generalise the threshold detector to an operator \ensuremath{\,??\,} that takes
a predicate (i.e., a function of type \ensuremath{\alpha\to \Conid{Bool}}), applies it to the
instantaneous value of a signal, and generates an event whenever
the predicate \emph{becomes} true. For instance,
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${(\lambda \Varid{x}\to \Varid{x}\mathbin{>}\mathrm{5})\,??\,\Varid{s}}$
\end{tabbing}denotes the event that occurs whenever the value of the signal \ensuremath{\Varid{s}}
starts to satisfy the predicate \ensuremath{\lambda \Varid{x}\to \Varid{x}\mathbin{>}\mathrm{5}}; i.e., whenever it becomes greater
than 5 after having been smaller. The expression \ensuremath{(\lambda \Varid{x}\to \Varid{x}\mathbin{>}\mathrm{5})\,??\,\Varid{s}} thus defines a threshold detector restricted to threshold
crossings with a positive slope.
 
Table S1 in the supplementary information presents an informal overview of
the syntax of CoPE; Table S2 details the types and names of some of
the functions we have defined using these definitions.

% \subsubsection{Observing signals and events}
\subsubsection*{Interacting with the physical world}

In the previous examples, signals, events and durations exist as purely
mathematical objects. To describe experiments, however, it must also
be possible to observe particular values from real-world systems, and to
create controlled stimuli to perturb these systems. For this purpose, we
introduce \emph{sources} and \emph{sinks} that act as a bridge between 
purely mathematical equations and the physical world.

A source is an input port through which the value of some external
quantity can be observed during the course of an experiment by binding
it to a variable. If the quantity is time-varying, the bound variable
will denote a signal. For instance, binding a variable to source
denoting a typical analog-to-digital converter yields a signal of real
numbers. However, a source may also refer to a time-invariant quantity.

The construct
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{identifier}\,<\!\!\!*\,\,\Varid{source}}$
\end{tabbing}binds the value or signal resulting from the observation of the
\emph{source} during the course of an experiment to the variable
\emph{identifier}. For a concrete example, the following code defines
a simple experiment:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{v}\,<\!\!\!*\,\,\Conid{ADC}\;\mathrm{0}}$
\end{tabbing}This describes the observation of the voltage signal on channel 0 of
an analog-to-digital converter, binding the whole signal to the
variable \ensuremath{\Varid{v}}. We have also used sources to sample values from
probability distributions (see Supplementary Information).

In addition to making appropriate observations, an experiment may also
involve a perturbation of the experimental preparation. For example,
the manipulation could control the amount of electric current injected
into a cell. Alternatively, non-numeric signals are used below to
generate visual stimuli on a computer screen. Such manipulations
require the opposite of a source, a \emph{sink}: an output port connected
to a physical device capable of effecting the
desired perturbation. The value at the output at any point in time
during an experiment is defined by connecting the corresponding sink
to a signal.  This is done through the the following construct,
mirroring the source construct introduced above:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{signal}\,\,*\!\!\!>\,\Varid{sink}}$
\end{tabbing}
As a concrete example, suppose we wish to output a sinusoidal
stimulus. We first construct a time-varying signal describing the
desired shape of the stimulus. In this case, we read a clock source
that yields a signal counting the number of seconds since the
experiment started:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{seconds}\,<\!\!\!*\,\,\Varid{clock}}$
\end{tabbing}The sine wave can now be defined as:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{sineWave}\mathrel{=}\Varid{smap}\;\Varid{sin}\;\Varid{seconds}}$
\end{tabbing}We then write
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{sineWave}\,\,*\!\!\!>\,\Conid{DAC}\;\mathrm{0}}$
\end{tabbing}{}
to send the \ensuremath{\Varid{sineWave}} signal to channel channel 0 of a
digital-to-analog converter. Below we show how
these primitives can be used to define two detailed experiments in
neurophysiology.
% Sinks and sources are thus used to
% link values, which have been or will be used in purely mathematical
% expressions, to the real world. There are also operations in
% experiments that are not related to real-world observation or to
% purely functional computation --- for instance sampling from
% probability distributions, which violates referentially transparancy
% (if $rnd$ is a random number generator with an arbitratry distribution
% parametrised by $\theta$, it is not in general the case that $ rnd
% \theta + rnd \theta = 2*rnd \theta$). We have thus implemented sources
% corresponding to common parametrised probability distributions, such
% that experiments can sample values from these distributions and use
% these values in computations or connect them to sinks. In this more
% general view, sources and sinks bridge referentially transparent and
% non-transparent computations.

\subsubsection*{Example 1}

In locusts, the Descending Contralateral Movement Detector (DCMD)
neuron signals the approach of looming objects to a distributed
nervous system \citep{Rind1992}. We have constructed several
experiments in CoPE to record the response of DCMD to visual stimuli
that simulate objects approaching with different velocities. To
generate these stimuli, we augmented CoPE with primitive
three-dimensional geometric shapes. Let the expression
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{cube}\;\Varid{l}}$
\end{tabbing}denote a cube centred on the origin, with side length \ensuremath{\Varid{l}},
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{translate}\;(\Varid{x},\Varid{y},\Varid{z})\;\Varid{s}}$
\end{tabbing}the shape that results from translating the shape \ensuremath{\Varid{s}} by the
vector \ensuremath{(\Varid{x},\Varid{y},\Varid{z})} and
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{colour}\;(\Varid{r},\Varid{g},\Varid{b})\;\Varid{s}}$
\end{tabbing}the shape identical to \ensuremath{\Varid{s}} except with the colour intensity red \ensuremath{\Varid{r}},
green \ensuremath{\Varid{g}} and blue \ensuremath{\Varid{b}}. Additional constructors can be introduced for
more complex stimuli, but these are sufficient for the experiments
reported here. Since signals in CoPE are polymorphic, they can carry not just
numeric values but also shapes, so we represent visual stimuli as
values in \ensuremath{\Conid{Signal}\;\Conid{Shape}}. The looming stimulus consists of a cube of
side length l approaching a locust with constant velocity v. The
time-varying distance from the locust to the cube in real-world
coordinates is a real-valued signal:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{distance}\mathrel{=}\{\!:\!\;\Varid{v}\!\cdot\!(\langle:\Varid{seconds}:\rangle\mathbin{-}\mathrm{5})\;\!:\!\}}$
\end{tabbing}
The \ensuremath{\Varid{distance}} signal is the basis of shape-valued signal
\ensuremath{\Varid{loomingSquare}} representing the approaching square:

\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{loomingSquare}\mathrel{=}}$\\
${\hskip2.50em\relax\{\!:\!\;\Varid{colour}\;(\mathrm{0},\mathrm{0},\mathrm{0})\;}$\\
${\hskip2.50em\relax\phantom{\{\!:\!\;\Varid{colour}\;\mbox{}}(\Varid{translate}\;(\mathrm{0},\mathrm{0},\langle:\Varid{distance}:\rangle)\;}$\\
${\hskip2.50em\relax\phantom{\{\!:\!\;\Varid{colour}\;\mbox{}}\phantom{(\Varid{translate}\;\mbox{}}(\Varid{cube}\;\Varid{l}))\;\!:\!\}}$
\end{tabbing}
\ensuremath{\Varid{loomingSquare}} differs from conventional protocols
\citep{Gabbiani2001} for stimulating DCMD in that it describes an
object that passes through the physical screen and the observer, and
when displayed would thus disappear from the screen just before
collision. In order not to evoke a large OFF response
\citep{O'shea1976} at this point, the object
is frozen in space as it reaches the plane of the surface onto which
the animation is projected \citep{Hatsopoulos1995}. To achieve this
effect, we define a new signal that has a lower bound of the distance
from the eye to the visual display screen \ensuremath{z_{screen}}
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{distance'}\mathrel{=}\{\!:\!\;\Varid{max}\;z_{screen}\;\,\langle:\Varid{distance}:\rangle\!:\!\}}$
\end{tabbing}where \ensuremath{\Varid{max}\;\Varid{x}\;\Varid{y}} returns the larger of the two numbers \ensuremath{\Varid{x}} and
\ensuremath{\Varid{y}}. \ensuremath{\Varid{loomingSquare'}} is identical to \ensuremath{\Varid{loomingSquare}} except for the
use of \ensuremath{\Varid{distance'}}.

Finally, \ensuremath{\Varid{loomingSquare'}} is connected to a screen signal sink that
represents a visual display unit capable of projecting
three-dimensional shapes onto a two-dimensional surface.
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{loomingSquare'}\,\,*\!\!\!>\,\Varid{screen}}$
\end{tabbing}In our experiments, the extracellular voltage from the locust nerve
(connective), in which the DCMD forms the largest amplitude spike,
was amplified, filtered (see methods) and digitised:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{voltage}\,<\!\!\!*\,\,\Conid{ADC}\;\mathrm{0}}$
\end{tabbing}\ensuremath{\Varid{loomingSquare'}} and \ensuremath{\Varid{voltage}} thus define a single object approach
and the recording of the elicited response. This approach was repeated
every 4 minutes, with different values of $\frac{l}{|v|}$. Figure 1
shows $\frac{l}{|v|}$ as values with type \ensuremath{\Conid{Duration}\;\mathbb{R}}, together
with the \ensuremath{\Varid{distance'}} and \ensuremath{\Varid{voltage}} signals for the first five trials
of one experiment on a common time scale.

The simplest method for detecting spikes from a raw voltage trace is
to search for threshold crossings, which works well in
% HN 2010-11-24: Note: practice is the noun, practise the verb 
practice for calculating DCMD activity from recordings of the locust
connectives \citep{Gabbiani2001}. If the threshold voltage for spike
detection is \ensuremath{v_{th}}, the event \ensuremath{\Varid{spike}} can be calculated with
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{spike}\mathrel{=}\Varid{tag}\;()\;((\lambda \Varid{v}\to \Varid{v}\mathbin{>}v_{th})\,??\,\Varid{voltage})}$
\end{tabbing}where \ensuremath{\Varid{tag}} replaces every tag in some event with a fixed value, so
that spike has type \ensuremath{\Conid{Event}\;()}. This event is displayed on the common
time scale in Figure 1. The top row displays the spike rate histogram
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${H_{spike}\mathrel{=}}$\\
${\phantom{H_{spike}\mbox{}}\{\!:\!\;\Varid{length}\;(\Varid{filter}\;(\Varid{between}\langle:\Varid{delay}\;\Varid{seconds}:\rangle}$\\
${\phantom{H_{spike}\mbox{}}\phantom{\{\!:\!\;\Varid{length}\;(\Varid{filter}\;(\Varid{between}\mbox{}}\langle:\Varid{seconds}:\rangle\mathbin{\circ}\Varid{fst})\;}$\\
${\phantom{H_{spike}\mbox{}}\phantom{\{\!:\!\;\Varid{length}\;(\Varid{filter}\;\mbox{}}\Varid{spikes})\;\!:\!\}}$
\end{tabbing}for each trial. This definition exploits the list semantics of events
by using the generic list-processing function \ensuremath{\Varid{filter}} which takes as
arguments predicate \ensuremath{\Varid{p}} and a list \ensuremath{\Varid{xs}}, and returns the list of
elements in \ensuremath{\Varid{xs}} for which the predicate holds. Here the predicate is
\ensuremath{\Varid{fst}} (which returns the first element of a pair, here the occurrence
time) composed (\ensuremath{\mathbin{\circ}}) with the function \ensuremath{\Varid{between}\mathrel{=}\lambda \Varid{x}\to \lambda \Varid{y}\to \lambda \Varid{z}\to \Varid{z}\mathbin{>}\Varid{x}\mathrel{\wedge}\Varid{z}\leq \Varid{y}}, which tests whether the last of three numbers lies
between the first two.

We examined how the DCMD spike response varied with changes in
$\frac{l}{|v|}$. The average of \ensuremath{H_{spike}} for three different values
of $\frac{l}{|v|}$ are shown in Figure 2A; 2B and 2C show the total
number of spikes (\ensuremath{\Varid{length}\;\Varid{spike}}) and largest value of \ensuremath{H_{spike}}, for
each approach, plotted against the value of $\frac{l}{|v|}$
\citep{Hatsopoulos1995}.

This experiment demonstrates that the calculus of physiological
evidence can adequately and concisely describe visual stimuli, spike
recording and relevant analyses for activation of a locust looming
detection circuit (see supplementary information for full code
listings.) To demonstrate the versatility of this framework, we next
show that it can be used to implement dynamic clamp in an \emph{in
  vivo} patch clamp recording experiment.

\subsubsection*{Example 2}

Dynamic clamp experiments \citep{Robinson1993, Sharp1993} permit the
observation of real neuronal responses to added simulated ionic
conductances; for instance, a synaptic conductance or an additional
Hodgkin-Huxley type voltage-sensitive membrane conductance. A dynamic
clamp experiment requires that the current injected into a cell is
calculated at every timepoint based on the recorded membrane
potential. Here, we use CoPE to investigate the effect of an A-type
potassium conductance \citep{Connor1971} on the response of a zebrafish
spinal motor neuron to synaptic excitation.

The output current
%
% HN 2010-11-24: I agree that one might call the syntactic category
% that encompass both equations and source/sink bindings "command" for
% want of a better term, but I think that talking about "commands"
% here is a bit confusing and might give the wrong impressions (imperative
% connotations). In any case, the notion of "command" has not been discussed
% before.
%
% command
\ensuremath{\Varid{i}} is calculated at each time-step from the simulated conductance \ensuremath{\Varid{g}}
and the measured membrane voltage \ensuremath{\Varid{v}}:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{v}\,<\!\!\!*\,\,\Conid{ADC}\;\mathrm{0}}$\\
${\Varid{i}\mathrel{=}\{\!:\!\;(\langle:\Varid{v}:\rangle\mathbin{-}\Conid{E})\!\cdot\!\langle:\Varid{g}:\rangle\!:\!\}}$\\
${\Varid{i}\,\,*\!\!\!>\,\Conid{DAC}\;\mathrm{0}}$
\end{tabbing}The experiment is thus characterised by the conductance signal $g$
(for clarity, here we omit the amplifier-dependent input and output
gains).

In the simplest case, $g$ is independent of $v$; for instance, when
considering linear synaptic conductances \citep{Mitchell2003}. We
first consider the addition of a simulated fast excitatory synaptic
conductance to a real neuron. Simple models of synapses approximate
the conductance waveform with an alpha function
\citep{Carnevale2006}:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${alpha_f\mathrel{=}\lambda \Varid{amp}\to \lambda \tau\to \{\!:\!\;\tau^\mathrm{2}\!\cdot\!\langle:\Varid{seconds}:\rangle\!\cdot\!\Varid{exp}\;(\mathbin{-}\langle:\Varid{seconds}:\rangle\!\cdot\!\tau)\;\!:\!\}}$
\end{tabbing}
To simulate a barrage of synaptic input to a cell, this waveform is
convolved with a simulated presynaptic spike train. The spike train
itself is first bound from a source representing a random probability
distribution, in this case series of recurrent events of type \ensuremath{\Conid{Event}\;()} for which the inter-occurrence interval is Poisson distributed.
Our standard library contains a function \ensuremath{\Varid{convolveSE}} which
convolves an impulse response signal with a numerically-tagged event,
such that the impulse response is multiplied by the tag before
convolution.
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{preSpike}\,<\!\!\!*\,\,\Varid{poissonTrain}\;\Varid{rate}}$\\
${g_{syn}\mathrel{=}\Varid{convolveSE}\;(alpha_f\;\Varid{amp}\;\tau)\;(\Varid{tag}\;\mathrm{1}\;\Varid{preSpike})}$
\end{tabbing}The signal \ensuremath{g_{syn}} could be used directly in a dynamic clamp experiment
using the above template (i.e. \ensuremath{\Varid{g}\mathrel{=}g_{syn}}). Here, we will examine other conductances
that modulate the response of the cell to synaptic excitation.

Both the subthreshold properties of a cell and its spiking rate can be
regulated by active ionic conductances, which can also be examined
with the dynamic clamp. In the Hodgkin-Huxley formalism for ion
channels, the conductance depends on one or more state variables, for
which the forward and backward rate constants depend on the membrane
voltage. We show the equations for the activation gate of an A-type
potassium current (\citep{Connor1971}; following \citep{Traub1991},
but using SI units and absolute voltages). The equations for
inactivation are analogous (see Listing 2 in supplementary
information).

We write the forward and backward rates as functions of the membrane voltage

\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\alpha_a\mathrel{=}\lambda \Varid{v}\to \frac{\mathrm{20}\!\cdot\!(\mathbin{-}\mathrm{46.9}\mathbin{-}\Varid{v}\!\cdot\!\mathrm{1000})}{\Varid{exp}\;\frac{\mathbin{-}\mathrm{46.9}\mathbin{-}\Varid{v}\!\cdot\!\mathrm{1000}}{\mathrm{10}}\mathbin{-}\mathrm{1}}}$\\
\\
${\beta_a\mathrel{=}\lambda \Varid{v}\to \frac{\mathrm{17.5}\!\cdot\!(\Varid{v}\!\cdot\!\mathrm{1000}\mathbin{+}\mathrm{19.9})}{\Varid{exp}\;\frac{\Varid{v}\!\cdot\!\mathrm{1000}\mathbin{+}\mathrm{19.9}}{\mathrm{10}}\mathbin{-}\mathrm{1}}}$
\end{tabbing}

%
%\begin{code}
%alphaa = \v->  20*(-46.9-v*1000)/(exp ((-46.9-v*1000)/10) -1)
%betaa = \v->   17.5*(v*1000+19.9)/(exp ((v*1000+19.9)/10) -1)
%\end{code}

The time-varying state of the activation gate is given by a
differential equation. We use the notation \ensuremath{\Conid{D}\;\Varid{x}\mathrel{=}\{\!:\!\;\Varid{f}\;(\Varid{x},\langle:\Varid{seconds}:\rangle)\;\!:\!\}} to denote the ordinary differential equation
that is conventionally written $\frac{dx}{dt} = f(x,t) $ with starting
conditions explicitly assigned to the variable $x_0$. The
differential equation for the activation variable $a$ is
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Conid{D}\;\Varid{a}\mathrel{=}\{\!:\!\;\alpha_a\langle:\Varid{vm}:\rangle\!\cdot\!(\mathrm{1}\mathbin{-}\langle:\Varid{a}:\rangle)\mathbin{-}}$\\
${\phantom{\Conid{D}\;\Varid{a}\mathrel{=}\{\!:\!\;\mbox{}}\beta_a\langle:\Varid{vm}:\rangle\!\cdot\!\langle:\Varid{a}:\rangle\!:\!\}}$\\
${a_0\mathrel{=}\mathrm{0}}$
\end{tabbing}The inactivation state signal \ensuremath{\Varid{b}} is defined similarly.

The current signal from this channel is calculated from Ohm's law:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${i_{A}\mathrel{=}\{\!:\!\;g_{A}\!\cdot\!\langle:\Varid{a}:\rangle\!\cdot\!\langle:\Varid{b}:\rangle\!\cdot\!(\langle:\Varid{v}:\rangle\mathbin{-}\Conid{E})\;\!:\!\}}$
\end{tabbing}This is added to the signal \ensuremath{\Varid{i}} defined above to give the output current
% command, 
thus completing the definition of this experiment:
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{i}\mathbin{+}i_{A}\,\,*\!\!\!>\,\Conid{DAC}\;\mathrm{0}}$
\end{tabbing}
Figure 3A and 3B show the voltage response to a unitary synaptic
conductance and a train of synaptic inputs, respectively, with \ensuremath{g_{A}}
ranging from 0 to 100 nS. By varying the value of \ensuremath{\Varid{rate}}, we can
examine the input-output relationship of the neuron by measuring the
frequency of postsynaptic spikes. Spikes were detected from the first
derivative of the \ensuremath{\Varid{v}} signal with
\begin{tabbing}
\qquad\=\hspace{\lwidth}\=\hspace{\cwidth}\=\+\kill
${\Varid{spike}\mathrel{=}\Varid{tag}\;()\;((\lambda \Varid{v'}\to \Varid{v'}\mathbin{>}\Varid{vth'})\,??\,\Conid{D}\;\Varid{v})}$
\end{tabbing}and the spike frequency calculated with the \ensuremath{\Varid{frequencyDuring}} function.
This relationship between the postsynaptic spike frequency and the
simulated synaptic input \ensuremath{\Varid{rate}} is plotted in Figure 3C for four
different values of \ensuremath{g_{A}}. 
\section*{Discussion}

We present a new approach to performing and communicating
experimental science.  Our use of
typed, functional and reactive programming overcomes at least three
long-standing issues in bioinformatics: the need for a flexible
ontology to share heterogeneous data from physiological experiments
\citep{Amari2002}, a language for describing experiments unambiguously
\citep{Murray-Rust2002}, and an equational formulation of data
provenance \citep{Pool2002}. 

The types we have presented form a linguistic framework and an
ontology for physiology. Thanks to the flexibility of parametric
polymorphism, our ontology can form the basis for the interchange of
physiological data and meta-data without imposing unnecessary
constraints on what can be shared. The ontology is non-hierarchical
and would be difficult to formulate in the various existing semantic
web ontology frameworks (Web Ontology Language, \citep{owlref}, or
Resource Description Framework), which lack parametric polymorphism
and functional abstraction. Nevertheless, by specifying the categories
of mathematical objects that constitute evidence, it is an ontology in
the classical sense of cataloguing the categories within a specific
domain, and providing a vocabulary for that domain. We emphasise again
that it is an ontology of \emph{evidence}, not of the biological
entities that give rise to this evidence. It is unusual as an ontology
for scientific knowledge in being embedded in a \emph{computational}
framework, such that it can describe not only mathematical objects but
also their transformations and observations. We make no distinction between
the representation of data and meta-data \citep{Bower2009,
  Gibson2008}. All relevant information about an experiment is stored
as signals, events or durations, which are all indexed by time and
thus linked by overlap on a common time scale.

% HN 2010-11-24: Instead of
%
% Our mathematical definitions are less ambiguous than definitions
% written in plain English, 
% 
% to make it consistent with "unambiguous" above, I propose
%
Our mathematical definitions are unambiguous and concise, unlike
typical definitions written in natural language, and are more powerful
than those specified by graphical user interfaces or in formal
languages that lack a facility for defining abstractions. Our
framework is not only a theoretical formalism, but we also demonstrate
that it can be implemented as a very practical tool. This tool
consists of a collection of computer programs for executing
experiments and analyses, and carrying out data
management. Controlling experimentation and analysis with programs
that share data formats can be highly efficient, and eliminates many
sources of human error. Existing tools use differential equations to
define dynamic clamp experiments (Model Reference Current Injection
(MRCI); \citep{Raikov2004}) or simulations (X-Windows Phase Plane
(XPP); \citep{Ermentrout1987}). Here, we show that a general (polymorphic)
defintion of signal and events, embedded in the lambda calculus, can
define a much larger range of experiments, and the evidence that they
produce. Our experiment definitions have the further advantage that
they \emph{compose}; that is, more complex experiments can be
formulated by joining together elementary building blocks.


Our full approach is particularly relevant to the execution of very
complex and multi-modal experiments, which may need to be dynamically
reconfigured based on previous observations, or to disambiguate
difficult judgements about evidence \citep{Kriegeskorte2009}. Even
if used separately, however, individual aspects of CoPE can make
distinct contributions to scientific methodology. For instance, our
ontology for physiological evidence can be used within more
conventional programming languages or web applications that facilitate
data sharing. In a similar way, the capabilities of CoPE for executing
and analysing experiments could provide a robust core for innovative
graphical user interfaces.

A corollary of our work is that it may be possible in principle to
mechanically verify scientific inference, just as mathematical proofs
can be verified by a proof checker \citep{DeBruijn1968,
  Harrison2009}. It is of course not possible to verify particular
hypotheses about the physical world, or an organism in this way. What
might be verifiable are statements about experiments --- for instance,
that: particular variables were randomly controlled and not observed;
outcomes have not gained correlation due to the analysis procedure;
missing data are accounted for by the statistical model
\citep{Gelman2003}; errors are propagated correctly \citep{Taylor1997};
units of measurement are used consistently \citep{Kennedy1997}; there
is no ``double dipping'' \citep{Kriegeskorte2009}; and, ultimately,
that the observed data support the conclusions drawn. Statistical
analyses address some of these issues in relating observations to
parameter estimation and hypothesis testing. Without knowing
where observations come from, however, it is difficult to ascertain whether
they provide evidence for a given scientific hypothesis
\citep{Pool2002}. Experiment description languages, and the
representation of experimental observations into values of concrete
types (which may not always be real numbers), could play an important
role in such inference. It is likely that at least some aspects of
validation in physiology can be achieved with conservative extensions
of
% the calculus of physiological evidence 
CoPE integrated with statistical inference.

\section*{Experimental Procedures}

\subsubsection*{Language implementation}

We have used two different implementation strategies for reasons of
rapid development and execution efficiency. For purposes of
experimentation and simulation, we have implemented a prototype
compiler that can execute some programs that contain signals and
events defined by mutual recursion, as is necessary for the
experiments in this paper. The program is transformed by the compiler
into a normal form that is translated to an imperative program which
iteratively updates variables corresponding to signal values, with a
time step that is set explicitly. The program is divided into a series
of stages, where each stage consists of the signals and events defined
by mutual recursion, subject to the constraints of input/output
sources and sinks. This ensures that signal expressions can reference
values of other signals at arbitrary time points (possibly in the
future) as long as referenced signals are computed in an earlier
stage.

To calculate a new value from existing observations after data
acquisition, we have implemented the calculus of physiological
evidence as a domain-specific language embedded in the purely functional
programming language Haskell.

For hard real-time dynamic-clamp experiments, we have built a compiler
back-end targeting the LXRT (user-space) interface to the RTAI (Real-time
application interface; \url{http://rtai.org}) extensions of the Linux
kernel, and the Comedi (\url{http://comedi.org}) interface to data
acquisition hardware. Geometric shapes were rendered using OpenGL
(\url{http://opengl.org}).

All code used for experiments, data analysis and generating figures is
available at \url{http://github.com/glutamate/bugpan} under the GNU General
Public License (GPL).

\subsubsection*{Locust experiments}

Recordings from locust DCMD neurons were performed as previously
described \citep{Matheson2004}. Briefly, locusts were fixed in
plasticine with the ventral side upwards. The head was fixed with wax
% at a $90^{\circ}$ angle
and the connectives were exposed through an
incision in the soft tissue of the neck. A pair of silver wire hook
electrodes were placed underneath a connective and the electrodes
and connective enclosed in petroleum jelly. The electrode signal was
amplified 1000x and bandpass filtered 50--5000 Hz, before
analog-to-digital conversion at 18 bits and 20 kHz with a National
Instruments PCI-6281 board. The locust was placed in front of a 22''
CRT monitor running with a vertical refresh rate of 160 Hz. All
aspects of the visual stimulus displayed on this monitor and of
the analog-to-digital conversion performed by the National Instruments
board were controlled by programs written in
% the calculus of physiological evidence
CoPE running on a single computer.

\subsubsection*{Zebrafish experiments}

Intracellular patch-clamp recordings from motor neurons in the spinal
cord of a 2-day old zebrafish embryo were performed as previously
described \citep{McDearmid2006}. We used a National Instruments PCI-6281
board to
record the output from a BioLogic patch-clamp amplifier in
current-clamp mode, filtered at 3kHz and digitised at 10 kHz, with the
output current calculated at the same rate by programs written in
% the calculus of physiological evidence
CoPE targeted to the RTAI backend (see
above). The measured jitter for updating the output voltage was 6
$\mu$s and was similar to that measured with the RTAI latency test
tool for the experiment control computer.

\subsubsection*{Author Contributions}  

T.N. designed and implemented CoPE, carried out the experiments and
data analyses, and wrote the draft of the paper. H.N. contributed to
the language design, helped clarify the semantics, and wrote several
sections of the manuscript. T.M. contributed to the design of the
experiments and the data analysis, and made extensive comments on
drafts of the manuscript. All authors obtained grant funding to
support this project as described in the acknowledgements.

\subsubsection*{Acknowledgements}  

We would like to thank Jonathan McDearmid for help with the Zebrafish
recordings and Angus Silver, Guy Billings, Antonia Hamilton, Nick
Hartell and Rodrigo Quian Quiroga for critical comments on the
manuscript. This work was funded by a Human Frontier Science Project
fellowship to T.N., a Biotechnology and Biological Sciences Research
Council grant to T.M. and T.N., and Engineering and Physical Sciences Research
Council grants to H.N.




\bibliographystyle{unsrt}
\bibliography{paper}

\pagebreak

\section* {Figure and Table Legends}

\textbf{Figure 1}. Diagram of an experiment to record the looming
response from a locust DCMD neuron, showing the first five recorded
trials from one animal. Experiment design: \emph{blue lines},
simulated object size-to-approach speed ratio ($\frac{l}{|v|}$) for
given approach trial, \emph{red lines}, simulated object distance,
\emph{red triangles}, apparent collision time. Observed signal:
\emph{black lines}, recorded extracellular voltage. The largest
amplitude deflections are DCMD spikes. Analysis: \emph{green dots},
DCMD spikes, with randomly jittered vertical placement for display,
\emph{thin black line}, spike rate histogram with 50 ms bin size. The
inter-trial interval of four minutes is not shown.

\flushleft \textbf{Figure 2}. A, Spike rate histograms for approaches with
$\frac{l}{|v|}$ of 0.01, 0.02 and 0.04 s, with 50 ms bin size, with
collision time indicated by a black triangle. B, Scatter plot of
number of counted spikes against approach $\frac{l}{|v|}$ for
individual trials. C, Scatter plot of the maximum rate of spiking
against $\frac{l}{|v|}$ for individual trials. N=1 animal, 272
approaches.

\flushleft \textbf{Figure 3}. A, recorded intracellular voltage following
conductance injections of a unitary simulated synaptic conductance, in
the presence of A-type potassium conductances of increasing magnitude
(values given are for the maximal conductance $g_A$). B, as A, but
with a simulated presynaptic spike train with inter-spike intervals
drawn from a Poisson distribution (here a mean of $120 s^{-1}$; the spike
trains used to test the different levels of A-type conductance are
identical). C, the postsynaptic spike rate plotted against the rate of
simulated presynaptic inputs, with $g_A$ as in A.


%\includepdf[pages=-]{Figure1.pdf}
%\includepdf[pages=-]{FigureDyn.pdf}
%\includepdf[pages=-]{Figure4.pdf}

%\begin{comment}
%\pagebreak
%\vskip1ex 

\flushleft \textbf{Table 1}. Representation of physiological
observations and quantities in CoPE

\pagebreak
%\includepdf[pages=-]{supplement.pdf}
\section*{Table 1}

\begin{tabular}{l  l}
\hline
  Quantity & Type \\ 
\hline
  Voltage across the cell membrane & \ensuremath{\Conid{Signal}\;\mathbb{R}} \\
  Ion concentration & \ensuremath{\Conid{Signal}\;\mathbb{R}} \\
  Animal location in 2D & \ensuremath{\Conid{Signal}\;(\mathbb{R}\;\!\!\times\!\!\;\mathbb{R})} \\
  Action potential & \ensuremath{\Conid{Event}\;()} \\
  Action potential waveforms & \ensuremath{\Conid{Event}\;(\Conid{Signal}\;\mathbb{R})} \\
  Spike detection threshold & \ensuremath{\Conid{Duration}\;\mathbb{R}} \\
  Spike interval & \ensuremath{\Conid{Duration}\;()} \\
  Synaptic potential amplitude & \ensuremath{\Conid{Event}\;\mathbb{R}} \\
  Drug present & \ensuremath{\Conid{Duration}\;()} \\
  Trial with parameter \ensuremath{\alpha} & \ensuremath{\Conid{Duration}\;\alpha} \\
  Visual stimulus & \ensuremath{\Conid{Signal}\;\Conid{Shape}} \\
  Lab notebook & \ensuremath{\Conid{Event}\;\Conid{String}} \\
\hline
\end{tabular}



\end{document}
 
